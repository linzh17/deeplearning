# 深层神经网络

## forward propagation in a deep network 
>$Z^{[1]}=W^{[1]}X+b^{{1}}$ \
$A^{[1]}=g^{[1]}(Z^{[1]})$ \
........ \
$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$ \
$A^{[l]}=g^{[l]}(Z^{[l]})$ 

## 核对矩阵的维数
## Building blocks of deep neural networks 
### Forward and backward function 
> Forward \
$input a^{[l-1]}$ \
$z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}$ \
$a^{[l]}=g^{[l]}(z^{[l]})$  

> Backward \
$Input da^{[l]}$ \ 
$output da^{[l-1]},dw^{[l]},db^{[l]}$  

### Hyperparameters 
> Learning rate  
> Iterations  
> Hidden layers  
> Hidden units  
> Choice of activation function     
> 