# 深度学习优化算法 


## Mini-batch 梯度下降
> 对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢  
> 但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为Mini-batch。
\

$x=[x^{(1)}....x^{m}]$  
e.g. 假设有500万个数据 ,则每1000个数据为一个mini-batch ,则有5000个mini-batch  
将一个mini-batch 表示为$x^{\{i\}}$

>对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。 

## 理解mini-batch 
>设mini-batch 大小为size  
if  size = m mini-batch 实际上为batch梯度下降  
if size = 1 mini-batch 实际上为随机梯度下降 SGD
* batch梯度下降： 
对所有m个训练样本执行一次梯度下降，每一次迭代时间较长；  
Cost function 总是向减小的方向下降。 

* 随机梯度下降：   
对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速；  
Cost function总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式。 

* Mini-batch梯度下降：   
也呈波动的下降,最终趋势为下降  
选择一个1<size<m1<size<m 的合适的size进行Mini-batch梯度下降，可以实现快速学习，也应用了向量化带来的好处。  
Cost function的下降处于前两者之间  

### mini-batch 的大小选择 

* 如果训练样本的大小比较小时，如m⩽2000m⩽2000时 —— 选择batch梯度下降法；  
* 如果训练样本的大小比较大时，典型的大小为：   
$2^6,2^7.....,2^10$
*  Mini-batch的大小要符合CPU/GPU内存  不然算法表现较差

![image](https://img-blog.csdn.net/20171011095046354?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29hbGFfVHJlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)  

## 指数加权平均  
> 指数加权公式 $v_t = \beta*v_{t-1}+(1-\beta)\theta_t$   
> 以每天的温度为例子 ,$v_t$代表t天的平均温度值,$\theta_t$代表第t天的温度值  
> $\beta$ 代表可调节的超参数值  

$\beta$=0.9的例子  
![image](https://pic2.zhimg.com/80/v2-d867aab342a51b94bf9ba54302138c9d_hd.jpg)  
化简得到的表达式  
![image](https://pic4.zhimg.com/80/v2-ab8fb1f005f9a0f17ff8d040ff0e276f_hd.jpg)  
> 通过上面表达式 可以看到  
> 本质就是以指数式递减加权的移动平均。各数值的加权而随时间而指数式递减，越近期的数据加权越重，但较旧的数据也给予一定的加权   
> 上式中所有θ前面的系数相加起来为1或者接近于1 称之为偏差修正  
> 当$(1-\delta)^{1/\delta} = \frac{1}{e}$  
>  $\beta=0.9$  
> 即 $0.9^10 \approx 0.35 \approx \frac{1}{e}$ 相当于大约十天后 系数的峰值下降到原来的1/e  
> 我们可以看到指数加权平均的求解过程实际上是一个递推的过程，那么这样就会有一个非常大的好处，每当我要求从0到某一时刻（n）的平均值的时候，我并不需要像普通求解平均值的作为，保留所有的时刻值，类和然后除以n。  
> 而是只需要保留0-(n-1)时刻的平均值和n时刻的温度值即可。也就是每次只需要保留常数值，然后进行运算即可，这对于深度学习中的海量数据来说，是一个很好的减少内存和空间的做法。  

### 指数加权平均实现
> v0=0  
> v1=βv0+(1−β)θ1  
> v2=βv1+(1−β)θ2  
> v3=βv2+(1−β)θ3…

### 指数加权平均的偏差修正  
>解决初期平均值的偏差  
![image](https://img-blog.csdn.net/20171011110513055?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29hbGFfVHJlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)  
> 上图中,紫色线为起点较低,这就是初期平均值的偏差,远小与平均值 ,原因由公式 实现的公式可以发现,一开始的值会远小于实际值  

修正的方法  
使用$\frac{v_t}{1-\beta^t}$   
偏差修正得到了绿色的曲线,在开始的时候可以比紫色曲线更好的计算评价今年的效果,随着t的增大,$\beta^t$接近与0,绿色和紫色的曲线逐渐重合 

## 动量梯度下降 momentum  
> 动量梯度下降的基本思想就是计算梯度的指数加权平均数，并利用该梯度来更新权重。   

![image](https://img-blog.csdn.net/20171011150017694?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29hbGFfVHJlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)  

> 在利用梯度下降法来最小化该函数的时候，每一次迭代所更新的代价函数值如图中蓝色线所示在上下波动，而这种幅度比较大波动，减缓了梯度下降的速度，而且我们只能使用一个较小的学习率来进行迭代  
>   如果用较大的学习率，结果可能会如紫色线一样偏离函数的范围，所以为了避免这种情况，只能用较小的学习率

> 使用动量梯度下降算法,使用了指数加权平均的方法,纵轴方向上的上下波动,经过平均以后,接近于0,在横轴上,所有微分指向横轴,平均值依然很大,最后实现红色线的梯度下降曲线

算法实现  
![image](https://img-blog.csdn.net/20171011151043703?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29hbGFfVHJlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)  
$v_{dw},v_{db}$初始值为0  


## RMSprop  
![image](https://img-blog.csdn.net/20171011154131345?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29hbGFfVHJlZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
 这里假设参数b的梯度处于纵轴方向，参数w的梯度处于横轴方向（当然实际中是处于高维度的情况），利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，如图中蓝色线所示，使其梯度下降的速度变得更快，如图绿色线所示。

在如图所示的实现中，RMSprop将微分项进行平方，然后使用平方根进行梯度更新，同时为了确保算法不会除以0，平方根分母中在实际使用会加入一个很小的值如$ε=10^{-8}$。

## Adam 优化算法  
> Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法  
### 算法实现  
*  初始化 $V_{dw}=0 ,V_{db}=0,S_{dw}=0,S_{db}=0$  
*  第t次迭代:  
    * compute dw,db on the current mini-batch 
    * $V_{dw}=\beta_{1}V_{dw}+(1-\beta_{1})dw,
        V_{db}=\beta_{1}V_{db}+(1-\beta_{1})db$  (momentum)
    * $S_{dw}=\beta_{2}S_{dw}+(1-\beta_{2})dw^2,
        S_{db}=\beta_{2}S_{db}+(1-\beta_{2})db^2$  (RMSprop)
    * $V^{corrected}_{dw}=V_{dw}/(1-\beta^a_{1}),
     V^{corrected}_{db}=V_{db}/(1-\beta^a_{1})$ (偏差修正)
    * $S^{corrected}_{dw}=S_{dw}/(1-\beta^a_{2}),
     S^{corrected}_{db}=S_{db}/(1-\beta^a_{2})$ (偏差修正)
    * $w:=w-\alpha\frac{V^{corrected}_{dw}}{\sqrt{S^{corrected}_{dw}+ε}},
     b:=b-\alpha\frac{V^{corrected}_{db}}{\sqrt{S^{corrected}_{db}+ε}}$ 

### 超参数的选择 
* α：需要进行调试；
* β1：常用缺省值为0.9，dw的加权平均；
* β2：推荐使用0.999，dw2的加权平均值；
* ε：推荐使用10−8。  
  
## 学习率衰减 
 * 常用 
        $\alpha = \frac{1}{1+decay-rate*epoch_num}\alpha_0$  
* 指数衰减 
        $\alpha  = 0.95^{epoch_num}\alpha_0$
